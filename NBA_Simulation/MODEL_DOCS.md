Model Overview

This repository contains a simulation-driven NBA modeling pipeline that:

- Backtests the simulator across a date range to evaluate prediction error
- Builds a team-level calibration from recent backtest results
- Runs calibrated simulations for today’s games to produce per-game and per-player summaries
- Reports the most accurate players (top performers) over a recent window
- Optionally emails a daily report

Key Components

- `simulation_engine.py`
  - Core game simulator and orchestration helpers.
  - Backtest: `backtest_simulation(start_date, end_date, simulations, rng_seed, write_outputs)`
  - Per-date simulation: `simulate_for_date(dt_pst, simulations, rng_seed, write_pbp)`
  - Calibration builder: `build_calibration_from_backtests(window_days, write)`
  - Today’s run: `run_today_simulations(write_pbp, simulations, rng_seed)`
  - Caching: per‑day backtest files written to `Backtest_cache/sim_backtest_{games|players}_YYYY-MM-DD.csv`

- `run_calibrated_sim.py`
  - CLI for the 3-step flow: Backtest → Calibrate → Sim Today
  - Fast toggles: `--sims`, `--fast`, `--bt-days` (limit backtest window)
  - Skips: `--skip-backtest`, `--skip-calibration`
  - Usage caps learning: `--learn-caps` (writes `usage_caps.csv`)
  - Top-performers report (default on): combined CSV `top_performers_all_lastN.csv`

- `learn_usage_caps.py`
  - Learns per-rank usage caps from historical box scores (`player_scores.csv`) as the p90 share of team FGAs.
  - Output: `usage_caps.csv` used by the simulator to set per-player usage caps by minutes rank.

- `daily_nba_top_performers_email.py`
  - Daily automation to run backtest + calibration + today + report, then email the combined CSV.
  - Env overrides: `BT_DAYS`, `BT_SIMS`, `TODAY_SIMS`, `REPORT_LAST_N`, `SENDER_EMAIL`, `SENDER_APP_PASSWORD`, `RECIPIENT_EMAIL`.

Inputs

By default, inputs live under `NBA_Simulation/` and can be overridden via `model_inputs.txt` (see next section):

- `player_scores.csv` — historical per‑player box scores (includes fields like `fga`, `min`, `totReb`, `assists`). Used for caps learning and validation.
- `filtered_game_scores.csv` — league and team recent scoring totals used to derive a pace baseline per matchup.
- `sim_calibration.csv` — team-level calibration file produced by backtests; loaded during simulations.
- `Backtest_cache/` — per-day backtest aggregates for games and players.
- `Play_by_Play/` — optional per-simulation play-by-play outputs.
- `usage_caps.csv` — learned usage caps (optional, generated by `learn_usage_caps.py`).

Outputs

- Backtest per-day cache: `Backtest_cache/sim_backtest_games_YYYY-MM-DD.csv`, `Backtest_cache/sim_backtest_players_YYYY-MM-DD.csv`
- Today’s summaries: `games_summary_today_YYYYMMDD.csv`, `players_summary_today_YYYYMMDD.csv`, `play_by_play_today_YYYYMMDD.csv`
- Team calibration: `sim_calibration.csv`
- Report: `top_performers_all_lastN.csv`

Configuration (`model_inputs.txt`)

Create or edit `NBA_Simulation/model_inputs.txt` to override paths used by the engine (key=value, one per line):

- `PLAYER_SCORES_FILE` — path to historical player box scores CSV
- `FILTERED_GAME_SCORES_FILE` — path to filtered game scores CSV
- `CALIBRATION_FILE` — path to team calibration CSV
- `BACKTEST_CACHE_DIR` — folder for per-day backtest cache files
- `PBP_DIR` — folder for optional PBP outputs
- `USAGE_CAPS_FILE` — path to learned usage caps CSV

Example `model_inputs.txt`:

PLAYER_SCORES_FILE=NBA_Simulation/player_scores.csv
FILTERED_GAME_SCORES_FILE=NBA_Simulation/filtered_game_scores.csv
CALIBRATION_FILE=NBA_Simulation/sim_calibration.csv
BACKTEST_CACHE_DIR=NBA_Simulation/Backtest_cache
PBP_DIR=NBA_Simulation/Play_by_Play
USAGE_CAPS_FILE=NBA_Simulation/usage_caps.csv

Common CLI Examples

- Quick iteration on a recent window:
  - `python NBA_Simulation/run_calibrated_sim.py --bt-days 7 --sims 10`

- Reuse cached backtests, rebuild calibration, run today:
  - `python NBA_Simulation/run_calibrated_sim.py --reuse-backtest --sims 20`

- Learn usage caps then run full flow:
  - `python NBA_Simulation/run_calibrated_sim.py --learn-caps --bt-days 14 --sims 20`

- Report only (from cache):
  - `python NBA_Simulation/run_calibrated_sim.py --report-only --report-last-n 5`

Backtest Details

Purpose
- Evaluate the simulator against actual game outcomes over a date range.
- Produce input data for calibration (team-level scalers).

How it runs
- Entry: `backtest_simulation(start_date=None, end_date=None, simulations=100, rng_seed=7, write_outputs=True)` in `simulation_engine.py`.
- Date range:
  - Explicit `--start-date/--end-date`, or
  - `--bt-days N` to auto-set the start date to the most recent N days.
- For each date:
  1) Build context (ratings, games, projected minutes) for that date.
  2) Run `simulate_for_date(dt, simulations=N)` to generate N simulation runs for each game.
  3) Summarize per game: mean/median of simulated final scores (home/away).
  4) Summarize per player: per-stat means/medians (points, rebounds, assists) across N sims.
  5) Compare to actuals on that date and compute errors.
  6) Write per-day cache files (always) in `Backtest_cache/`.

Aggregation and error metrics
- Game-level metrics per game (columns in `sim_backtest_games_YYYY-MM-DD.csv`):
  - `date_pst`, `home`, `away`, `sims`, `home_mean`, `home_median`, `away_mean`, `away_median`.
  - Backtest comparison uses mean-based predictions: `home_pred=home_mean`, `away_pred=away_mean`.
  - Errors in the combined frame: `home_error = home_mean - home_actual`, `away_error = away_mean - away_actual`.

- Player-level metrics per date (columns in `sim_backtest_players_YYYY-MM-DD.csv`):
  - From sims: `sims`, `mean_pts`, `median_pts`, `mean_reb`, `median_reb`, `mean_ast`, `median_ast`, plus identifiers (`team`, `player`, `date_pst`, `home`, `away`).
  - Matched to actuals by `team`/`team.code` and split first/last names.
  - Errors added when actuals available:
    - `player_points_error = mean_pts - actual_points`
    - `player_rebounds_error = mean_reb - actual_rebounds` (supports aliases like `totReb`, `tot_reb`, or sums `oreb+dreb`)
    - `player_assists_error = mean_ast - actual_assists` (supports `assists`/`ast`).

Caching behavior
- Per-day caches are written unconditionally after each date finishes:
  - Games: `Backtest_cache/sim_backtest_games_YYYY-MM-DD.csv`
  - Players: `Backtest_cache/sim_backtest_players_YYYY-MM-DD.csv`
- On subsequent runs, if a cache file exists for a date, it is loaded and that date is skipped (fast resume).

Calibration from backtests
- `build_calibration_from_backtests(window_days=30, write=True)` collects recent game caches from `Backtest_cache/`.
- Computes per-team offensive and defensive bias from sim-vs-actual points.
- Converts biases into gentle scalers around 1.0:
  - `off_ppp_scale`, `def_ppp_scale`, `shot_make_scale`, `opp_shot_make_scale`.
- Writes `sim_calibration.csv` used by the simulator.

Performance tips for backtest
- Reduce simulations with `--bt-sims` (or global `--sims`).
- Limit the backtest window with `--bt-days N`.
- Skip backtest entirely and reuse caches with `--skip-backtest`/`--reuse-backtest` when iterating.
- Control I/O: caches are per-day; optional end-of-run exports are disabled by default unless `--bt-write` is used.

Progress and transparency
- Prints progress per date: `[Backtest] i/N YYYY-MM-DD - X games, sims=Y`.
- Logs when a date is served from cache or written to cache.

File formats (selected columns)
- Games cache: `date_pst, home, away, sims, home_mean, home_median, away_mean, away_median`.
- Players cache: `team, player, sims, mean_pts, median_pts, mean_reb, median_reb, mean_ast, median_ast, date_pst, home, away, player.firstname, player.lastname, team.code` plus any merged actuals and error columns.
