import pandas as pd
import logging
import http.client
import json
import time
from datetime import datetime
from pytz import timezone

# Constants
REQUESTS_PER_MINUTE = 10
REQUESTS_PER_DAY = 20
LOG_FILE = "processed_games.log"
PLAYER_SCORES_FILE = "player_scores.csv"
NBA_GAME_SCORES_FILE = "nba_game_scores.csv"
FILTERED_GAME_SCORES_FILE = "filtered_game_scores.csv"

# Set up logging
logging.basicConfig(
    filename='check_and_pull_players.log',
    level=logging.DEBUG,
    format='%(asctime)s %(levelname)s:%(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def update_processed_games_log(player_scores_file, log_file):
    try:
        df = pd.read_csv(player_scores_file)
        game_ids = df['game.id'].unique()

        with open(log_file, "w") as file:
            for game_id in game_ids:
                file.write(f"{game_id}\n")

        logging.info(f"Processed games log updated with {len(game_ids)} game IDs from {player_scores_file}.")

        print(f"Processed games log updated with {len(game_ids)} game IDs.")
    except FileNotFoundError:
        logging.error(f"File {player_scores_file} not found.")
        print(f"File {player_scores_file} not found.")
    except Exception as e:
        logging.error(f"An error occurred: {e}")
        print(f"An error occurred: {e}")

def fetch_and_save_player_statistics(game_id, api_key):
    conn = http.client.HTTPSConnection("api-nba-v1.p.rapidapi.com")

    headers = {
        'x-rapidapi-key': api_key,
        'x-rapidapi-host': "api-nba-v1.p.rapidapi.com"
    }

    try:
        conn.request("GET", f"/players/statistics?game={game_id}", headers=headers)
        res = conn.getresponse()
        if res.status == 200:
            data = res.read()
            decoded_data = json.loads(data.decode("utf-8"))
            df = pd.json_normalize(decoded_data['response'])

            if 'team.logo' in df.columns:
                df = df.drop(columns=['team.logo'])

            df = df[df['comment'].isna()]  # Filter rows without comments
            sorted_df = df.sort_values(by='points', ascending=False)
            sorted_df['game.id'] = game_id
            logging.info(f"Fetched player statistics for game ID {game_id}")
            return sorted_df

        elif res.status == 429:
            logging.warning(f"Rate limit exceeded for game ID {game_id}. Waiting before retrying.")
            time.sleep(120)
            return fetch_and_save_player_statistics(game_id, api_key)

        else:
            logging.error(f"Error: {res.status} {res.reason} for game ID {game_id}")
            return None

    except Exception as e:
        logging.error(f"An error occurred for game ID {game_id}: {e}")
        return None

    finally:
        conn.close()

def get_nba_game_scores(season: int, api_key: str):
    conn = http.client.HTTPSConnection("api-nba-v1.p.rapidapi.com")

    headers = {
        'x-rapidapi-key': api_key,
        'x-rapidapi-host': "api-nba-v1.p.rapidapi.com"
    }

    conn.request("GET", f"/games?season={season}", headers=headers)
    res = conn.getresponse()

    if res.status != 200:
        logging.error(f"Error: {res.status} {res.reason} while fetching game scores")
        return None
    else:
        data = res.read()
        games = json.loads(data)

        game_data = []
        for game in games.get('response', []):
            game_id = game.get('id')
            game_date = game['date']['start']
            visitor_code = game['teams']['visitors']['code']
            home_code = game['teams']['home']['code']
            visitor_score = game['scores']['visitors']['points']
            home_score = game['scores']['home']['points']
            game_data.append({
                'game.id': game_id,
                'game_date': game_date,
                'visitor_score': visitor_score,
                'home_score': home_score,
                'visitor_code': visitor_code,
                'home_code': home_code
            })

        df = pd.DataFrame(game_data)
        df.to_csv(NBA_GAME_SCORES_FILE, index=False)
        logging.info(f"Game scores for season {season} saved to '{NBA_GAME_SCORES_FILE}'.")

        return df

def read_processed_games(log_file):
    try:
        with open(log_file, "r") as file:
            processed_games = set(line.strip() for line in file.readlines())
        logging.info(f"Read processed game IDs from {log_file}")
    except FileNotFoundError:
        processed_games = set()
        logging.info(f"{log_file} not found. Starting with an empty set of processed games.")
    return processed_games

def append_to_log_file(log_file, game_id):
    with open(log_file, "a") as file:
        file.write(f"{game_id}\n")
    logging.info(f"Appended game ID {game_id} to {log_file}")

def filter_games_before_today(csv_file):
    try:
        df = pd.read_csv(csv_file)
        df['game_date'] = pd.to_datetime(df['game_date'], errors='coerce')
        df = df.dropna(subset=['game_date'])

        pacific_time = timezone('US/Pacific')
        df['game_date_pacific'] = df['game_date'].apply(
            lambda x: x.tz_convert(pacific_time) if x.tzinfo else x.tz_localize('UTC').tz_convert(pacific_time)
        )

        df = df.dropna(subset=['visitor_score'])

        today_pacific = datetime.now(pacific_time).date()

        df_filtered = df[df['game_date_pacific'].dt.date < today_pacific]
        df_filtered.to_csv(FILTERED_GAME_SCORES_FILE, index=False)
        logging.info(f"Filtered game data saved to '{FILTERED_GAME_SCORES_FILE}'")

        return df_filtered

    except Exception as e:
        logging.error(f"An error occurred during date filtering: {e}")
        return pd.DataFrame()

def main():
    season = 2024
    api_key = "your_api_key_here"

    df = get_nba_game_scores(season, api_key)

    if df is not None:
        filtered_df = filter_games_before_today(NBA_GAME_SCORES_FILE)

        combined_results = pd.DataFrame()
        request_count = 0
        start_time = time.time()
        processed_games = read_processed_games(LOG_FILE)

        for i, game_id in enumerate(filtered_df['game.id']):
            game_id_str = str(game_id)
            if game_id_str in processed_games:
                logging.info(f"Game ID {game_id} already processed. Skipping.")
                continue

            if request_count >= REQUESTS_PER_DAY:
                logging.info("Daily request limit reached. Please run the script again tomorrow.")
                break

            if i % REQUESTS_PER_MINUTE == 0 and i != 0:
                elapsed_time = time.time() - start_time
                if elapsed_time < 60:
                    time.sleep(60 - elapsed_time)
                start_time = time.time()

            result_df = fetch_and_save_player_statistics(game_id=game_id, api_key=api_key)

            if result_df is None:
                logging.warning(f"No data returned for game ID {game_id}. Skipping.")
                continue

            combined_results = pd.concat([combined_results, result_df], ignore_index=True)
            combined_results.to_csv(PLAYER_SCORES_FILE, index=False)
            logging.info(f"Appended statistics for game ID {game_id} to {PLAYER_SCORES_FILE}")

            append_to_log_file(LOG_FILE, game_id)
            request_count += 1

if __name__ == "__main__":
    main()
